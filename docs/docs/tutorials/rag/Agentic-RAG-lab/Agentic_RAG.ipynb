{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LangChain agentic RAG system using the Granite-3-8B-Instruct model in watsonx.ai.\n",
    "\n",
    "\n",
    "**Author**: Anna Gutowska\n",
    "\n",
    "In this tutorial, you will create a LangChain agentic RAG system using the IBM [Granite-3-8B-Instruct model](https://www.ibm.com/granite) now available on [watsonx.ai](https://www.ibm.com/products/watsonx-ai) that can answer complex queries about the 2024 US Open using external information.\n",
    "\n",
    "\n",
    "# Overview of agentic RAG\n",
    "\n",
    "## What is RAG?\n",
    "\n",
    "[RAG](https://research.ibm.com/blog/retrieval-augmented-generation-RAG) is a technique in [natural language processing (NLP)](https://www.ibm.com/topics/natural-language-processing) that combines information retrieval and generative models to produce more accurate, relevant and contextually aware responses. In traditional language generation tasks, [large language models (LLMs)](https://www.ibm.com/topics/large-language-models) such as Meta's [Llama Models](https://llama.meta.com/) or IBM’s [Granite Models](https://www.ibm.com/granite) are used to construct responses based on an input prompt. Common real-world use cases of these large language models are chatbots. When models are missing relevant information that is up to date in their knowledge base, RAG is a powerful tool.\n",
    "\n",
    "## What are AI agents?\n",
    "\n",
    "At the core of agentic RAG systems are [artificial intelligence (AI)](https://www.ibm.com/topics/artificial-intelligence) agents. An [AI agent](https://www.ibm.com/think/topics/ai-agents) refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system by designing its workflow and using available tools. Agentic technology implements tool use on the backend to obtain up-to-date information from various data sources, optimize workflow and create subtasks autonomously to solve complex tasks. These external tools can include external data sets, search engines, APIs and even other agents. Step-by-step, the agent reassesses its plan of action in real time and self-corrects.  \n",
    "\n",
    "## Agentic RAG versus traditional RAG\n",
    "\n",
    "Agentic RAG frameworks are powerful as they can encompass more than just one tool. In traditional RAG applications, the LLM is provided with a vector database to reference when forming its responses. In contrast, agentic RAG implementations are not restricted to document agents that only perform data retrieval. RAG agents can also have tools for tasks such as solving mathematical calculations, writing emails, performing data analysis and more. These tools can be supplemental to the agent's decision-making process. AI agents are context-aware in their multistep reasoning and can determine when to use appropriate tools.\n",
    "\n",
    "AI agents, or intelligent agents, can also work collaboratively in [multiagent systems](https://www.ibm.com/think/topics/multiagent-system), which tend to outperform singular agents. This scalability and adaptability is what sets apart agentic RAG agents from traditional RAG pipelines. \n",
    "\n",
    "[![Open YouTube video](https://img.youtube.com/vi/Y1PaM3edYoI/0.jpg)](https://www.youtube.com/watch?v=Y1PaM3edYoI)\n",
    "\n",
    "This recipe is also available on [IBM.com](https://www.ibm.com/think/tutorials/agentic-rag).\n",
    "\n",
    "\n",
    "# Prerequisites\n",
    "\n",
    "You need an [IBM Cloud® account](https://cloud.ibm.com/registration) to create a [watsonx.ai™](https://www.ibm.com/products/watsonx-ai) project.\n",
    "\n",
    "# Steps\n",
    "\n",
    "## Step 1. Set up your environment\n",
    "\n",
    "While you can choose from several tools, this tutorial walks you through how to set up an IBM account to use a Jupyter Notebook. \n",
    "\n",
    "1. Log in to [watsonx.ai](https://dataplatform.cloud.ibm.com/registration/stepone?context=wx&apps=all) using your IBM Cloud account.\n",
    "\n",
    "2. Create a [watsonx.ai project](https://www.ibm.com/docs/en/watsonx/saas?topic=projects-creating-project).\n",
    "\n",
    "\tYou can get your project ID from within your project. Click the **Manage** tab. Then, copy the project ID from the **Details** section of the **General** page. You need this ID for this tutorial.\n",
    "\n",
    "3. Create a [Jupyter Notebook](https://www.ibm.com/docs/en/watsonx/saas?topic=editor-creating-managing-notebooks).\n",
    "\n",
    "This step will open a Notebook environment where you can copy the code from this tutorial.  Alternatively, you can download this notebook to your local system and upload it to your watsonx.ai project as an asset.\n",
    "\n",
    "## Step 2. Set up a watsonx.ai Runtime instance and API key.\n",
    "\n",
    "1. Create a [watsonx.ai Runtime](https://cloud.ibm.com/catalog/services/watsonxai-runtime) service instance (select your appropriate region and choose the Lite plan, which is a free instance).\n",
    "\n",
    "2. Generate an application programming interface [(API) key](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-authentication.html). \n",
    "\n",
    "3. Associate the watsonx.ai Runtime service instance to the project that you created in [watsonx.ai](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html). \n",
    "\n",
    "\n",
    "## Step 3. Install and import relevant libraries and set up your credentials\n",
    "\n",
    "We'll need a few libraries and modules for this tutorial. Make sure to import the following ones; if they're not installed, you can resolve this with a quick pip installation. \n",
    "\n",
    "Common Python frameworks for building agentic RAG systems include LangChain and LlamaIndex. In this tutorial, we will be using LangChain.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# installations\n",
    "!pip install -q git+https://github.com/ibm-granite-community/utils \\\n",
    "    langchain \\\n",
    "    langchain-ibm \\\n",
    "    langchain_community \\\n",
    "    ibm-watsonx-ai \\\n",
    "    ibm_watson_machine_learning \\\n",
    "    chromadb \\\n",
    "    tiktoken \\\n",
    "    bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pysqlite3-binary --quiet\n",
    "\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from langchain_ibm import WatsonxEmbeddings, WatsonxLLM\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools import tool\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your credentials. Please store your `WATSONX_PROJECT_ID` and `WATSONX_APIKEY` in a separate `.env` file in the same level of your directory as this notebook. Your `WATSONX_URL` will be dependent on your region. Reference the [documentation](https://cloud.ibm.com/apidocs/watsonx-ai) to determine the appropriate one for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ibm_granite_community.notebook_utils import get_env_var\n",
    "\n",
    "# credentials = {\n",
    "#     \"url\": get_env_var(\"WATSONX_URL\"),\n",
    "#     \"apikey\": get_env_var(\"WATSONX_APIKEY\")\n",
    "# }\n",
    "# project_id = get_env_var(\"WATSONX_PROJECT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Initialization a basic agent with no tools\n",
    "\n",
    "This step is important as it will produce a clear example of an agent's behavior with and without external data sources. Let's start by setting our parameters.\n",
    "\n",
    "The model parameters available can be found [here](https://ibm.github.io/watson-machine-learning-sdk/model.html). We experimented with various model parameters, including temperature, minimum and maximum new tokens and stop sequences. Learn more about model parameters and what they mean in the [watsonx docs](https://www.ibm.com/docs/en/watsonx/saas). It is important to set our `stop_sequences` here in order to limit agent hallucinations. This tells the agent to stop producing further output upon encountering particular substrings. In our case, we want the agent to end its response upon reaching an observation and to not hallucinate a human response. Hence, one of our stop_sequences is `'Human:'` and another is `Observation` to halt once a final response is produced.\n",
    "\n",
    "For this tutorial, we suggest using IBM's Granite-3-8B-Instruct model as the LLM to achieve similar results. You are free to use any AI model of your choice. The foundation models available through watsonx can be found [here](https://www.ibm.com/products/watsonx-ai/foundation-models). The purpose of these models in LLM applications is to serve as the reasoning engine that decides which actions to take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "INFERENCE_SERVER_URL = \"http://localhost:8989\"\n",
    "# MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\"\n",
    "API_KEY= \"alanliuxiang\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base= f\"{INFERENCE_SERVER_URL}/v1\",\n",
    "    model_name=MODEL_NAME,\n",
    "    top_p=0.92,\n",
    "    temperature=0.01,\n",
    "    max_tokens=512,\n",
    "    presence_penalty=1.03,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set up a prompt template in case you want to ask multiple questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Answer the {query} accurately. If you do not know the answer, simply say you do not know.\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can set up a chain with our prompt and our LLM. This allows the generative model to produce a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test to see how our agent responds to a basic query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I need to figure out what sport is played at the US Open. Hmm, I've heard of the US Open before, but I'm not exactly sure which sport it is. Let me think about this.\n",
      "\n",
      "First, I know there are several major sports in the United States, like baseball, basketball, football, and tennis. The US Open could refer to any of these, but I think it's more likely a specific event in one of them. I remember hearing about the US Open in the context of tennis tournaments. There's the Australian Open, French Open, Wimbledon, and US Open, which are all Grand Slam tennis events. So maybe the US Open is a tennis tournament?\n",
      "\n",
      "Wait, but I also recall that there's something called the US Open in golf as well. The US Open Golf Championship is one of the four majors in golf. So now I'm a bit confused because both tennis and golf have a US Open. How do I determine which one is being referred to when someone just says \"the US Open\"?\n",
      "\n",
      "I should consider the context in which the question is asked. If it's in a general conversation about sports, it might be either. But since the user is asking for an accurate answer, I need to be precise. Maybe I can think about when each US Open takes place. The tennis US Open usually happens in August or early September, while the golf US Open is around June or July. However, without knowing the exact timing, that might not help much.\n",
      "\n",
      "Another approach is to think about the names of the events. The tennis tournament is often referred to as the US Open, while the golf event is the US Open Golf Championship. But sometimes people just say US Open when talking about golf too. So how can I be certain?\n",
      "\n",
      "I think the most common association is with tennis because the US Open is one of the four Grand Slam tournaments, and it's widely publicized. Golf's US Open is also significant, but perhaps less commonly referred to simply as the US Open without specifying it's golf. Alternatively, maybe the user is referring to the tennis event because it's more globally recognized.\n",
      "\n",
      "Wait, I should also consider other sports. Is there a US Open in another sport? I don't think so. There's the US Open Cup in soccer, but that's a different event. So, putting it all together, the US Open is primarily known as a tennis tournament, but it's also associated with golf. Since the user didn't specify, I might need to clarify, but since I"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Okay, so I need to figure out what sport is played at the US Open. Hmm, I\\'ve heard of the US Open before, but I\\'m not exactly sure which sport it is. Let me think about this.\\n\\nFirst, I know there are several major sports in the United States, like baseball, basketball, football, and tennis. The US Open could refer to any of these, but I think it\\'s more likely a specific event in one of them. I remember hearing about the US Open in the context of tennis tournaments. There\\'s the Australian Open, French Open, Wimbledon, and US Open, which are all Grand Slam tennis events. So maybe the US Open is a tennis tournament?\\n\\nWait, but I also recall that there\\'s something called the US Open in golf as well. The US Open Golf Championship is one of the four majors in golf. So now I\\'m a bit confused because both tennis and golf have a US Open. How do I determine which one is being referred to when someone just says \"the US Open\"?\\n\\nI should consider the context in which the question is asked. If it\\'s in a general conversation about sports, it might be either. But since the user is asking for an accurate answer, I need to be precise. Maybe I can think about when each US Open takes place. The tennis US Open usually happens in August or early September, while the golf US Open is around June or July. However, without knowing the exact timing, that might not help much.\\n\\nAnother approach is to think about the names of the events. The tennis tournament is often referred to as the US Open, while the golf event is the US Open Golf Championship. But sometimes people just say US Open when talking about golf too. So how can I be certain?\\n\\nI think the most common association is with tennis because the US Open is one of the four Grand Slam tournaments, and it\\'s widely publicized. Golf\\'s US Open is also significant, but perhaps less commonly referred to simply as the US Open without specifying it\\'s golf. Alternatively, maybe the user is referring to the tennis event because it\\'s more globally recognized.\\n\\nWait, I should also consider other sports. Is there a US Open in another sport? I don\\'t think so. There\\'s the US Open Cup in soccer, but that\\'s a different event. So, putting it all together, the US Open is primarily known as a tennis tournament, but it\\'s also associated with golf. Since the user didn\\'t specify, I might need to clarify, but since I', additional_kwargs={}, response_metadata={'finish_reason': 'length', 'model_name': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B'}, id='run-0b911aa2-6067-4c00-b700-ac6946e35329-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"query\": \"What sport is played at the US Open?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent successfully responded to the basic query with the correct answer. In the next step of this tutorial, we will be creating a RAG tool for the agent to access relevant information about IBM's involvement in the 2024 US Open. As we have covered, traditional LLMs cannot obtain current information on their own. Let's verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I need to figure out where the 2024 US Open Tennis Championship was held. I'm not entirely sure off the top of my head, but I can try to work it out. Let me think about what I know regarding the US Open.\n",
      "\n",
      "First, I remember that the US Open is one of the four Grand Slam tennis tournaments, along with the Australian Open, Wimbledon, and the French Open. Each of these tournaments is held in a specific location every year. The US Open, as the name suggests, is in the United States. But where exactly?\n",
      "\n",
      "I think it's played in New York City. There's a famous tennis facility there called the USTA Billie Jean King National Tennis Center. That sounds familiar because I've heard it mentioned in news articles and sports highlights. The main stadium there is called Arthur Ashe Stadium, which is named after the legendary tennis player and social activist. So, putting that together, the US Open is held at the USTA Billie Jean King National Tennis Center in New York City.\n",
      "\n",
      "Wait, but I should make sure I'm not confusing it with another tournament. For example, the French Open is in Paris, Wimbledon in London, and the Australian Open in Melbourne. So yes, the US Open is indeed in New York. I don't think the location has changed recently, so it's safe to say that the 2024 US Open was held at the same place as previous years.\n",
      "\n",
      "I might also recall that the US Open typically takes place in late August or early September. The exact dates vary each year, but the venue remains consistent. Therefore, confirming that the location hasn't moved, the 2024 event would be at the USTA Billie Jean King National Tennis Center in New York City.\n",
      "</think>\n",
      "\n",
      "The 2024 US Open Tennis Championship was held at the USTA Billie Jean King National Tennis Center in New York City."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Okay, so I need to figure out where the 2024 US Open Tennis Championship was held. I'm not entirely sure off the top of my head, but I can try to work it out. Let me think about what I know regarding the US Open.\\n\\nFirst, I remember that the US Open is one of the four Grand Slam tennis tournaments, along with the Australian Open, Wimbledon, and the French Open. Each of these tournaments is held in a specific location every year. The US Open, as the name suggests, is in the United States. But where exactly?\\n\\nI think it's played in New York City. There's a famous tennis facility there called the USTA Billie Jean King National Tennis Center. That sounds familiar because I've heard it mentioned in news articles and sports highlights. The main stadium there is called Arthur Ashe Stadium, which is named after the legendary tennis player and social activist. So, putting that together, the US Open is held at the USTA Billie Jean King National Tennis Center in New York City.\\n\\nWait, but I should make sure I'm not confusing it with another tournament. For example, the French Open is in Paris, Wimbledon in London, and the Australian Open in Melbourne. So yes, the US Open is indeed in New York. I don't think the location has changed recently, so it's safe to say that the 2024 US Open was held at the same place as previous years.\\n\\nI might also recall that the US Open typically takes place in late August or early September. The exact dates vary each year, but the venue remains consistent. Therefore, confirming that the location hasn't moved, the 2024 event would be at the USTA Billie Jean King National Tennis Center in New York City.\\n</think>\\n\\nThe 2024 US Open Tennis Championship was held at the USTA Billie Jean King National Tennis Center in New York City.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B'}, id='run-0f4d6c44-0b2b-4d35-ad02-7e154ce81c4d-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"query\": \"Where was the 2024 US Open Tennis Championship?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, the LLM is unable to provide us with the relevant information. The training data used for this model contained information prior to the 2024 US Open and without the appropriate tools, the agent does not have access to this information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Establish the knowledge base and retriever\n",
    "\n",
    "The first step in creating the knowledge base is listing the URLs we will be extracting content from. In this case, our data source will be collected from our online content summarizing IBM’s involvement in the 2024 US Open. The relevant URLs are established in the `urls` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.ibm.com/case-studies/us-open\",\n",
    "    \"https://www.ibm.com/sports/usopen\",\n",
    "    \"https://newsroom.ibm.com/US-Open-AI-Tennis-Fan-Engagement\",\n",
    "    \"https://newsroom.ibm.com/2024-08-15-ibm-and-the-usta-serve-up-new-and-enhanced-generative-ai-features-for-2024-us-open-digital-platforms\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the documents using LangChain `WebBaseLoader` for the URLs we listed. We'll also print a sample document to see how it loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.ibm.com/case-studies/us-open', 'title': 'U.S. Open | IBM', 'description': 'To help the US Open stay on the cutting edge of customer experience, IBM Consulting built powerful generative AI models with watsonx.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\nU.S. Open | IBM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHome\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\nUS Open \\n\\n\\n\\n\\n                \\n\\n\\n\\n  \\n    Acing the US Open digital experience\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n                    \\n\\n\\n  \\n  \\n      AI models built with watsonx transform data into insight\\n  \\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\nGet the latest AI and tech insights\\n\\n\\n\\nLearn More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFor two weeks at the end of summer, nearly one million people make the journey to Flushing, New York, to watch the best tennis players in the world compete in the US Open Tennis Championships.\\nYear after year, it is one of the most highly attended sporting events in the world.\\n\\nBut more than 15 million global tennis fans follow the tournament through the US Open app and website. And to keep them coming back for more, the United States Tennis Association (USTA) has worked side-by-side with IBM Consulting® for more than three decades, developing and delivering a world-class digital experience that constantly advances its features and functionality.\\n\\n“The digital experience of the US Open is of enormous importance to our global fans, and therefore to us,” says Kirsten Corio, Chief Commercial Officer at the USTA. “That means we need to constantly innovate to meet the modern demands of tennis fans, anticipating their needs, but also surprising them with new and unexpected experiences.”\\nTo help the US Open stay on the cutting edge of customer experience, IBM Consulting worked closely with the USTA to develop generative AI models that transform tennis data into insights and original content on the US Open app and website. To do this, the USTA used IBM® watsonx™, a portfolio of AI products, and powerful AI models, including IBM Granite™ foundation models, to help develop key app features, such as Match Reports and AI Commentary for US Open highlight reels.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n      15M\\n  \\n\\n\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\nWorld-class digital experiences for more than 15 million fans around the globe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n      7M\\n  \\n\\n\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\nIBM captures and analyzes more than 7 million data points throughout the tournament\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n            \\n                \\n                     \\n                        \\n\\n\\n  \\n  \\n      The AI models built with watsonx do more than enhance the digital experience of the US Open. They also scale the productivity of our editorial team by automating key workflows.\\n  \\n\\n\\n\\n\\n    \\n\\n\\n                        \\n                \\n            \\n        \\n        \\n            Kirsten Corio\\n        \\n\\n            Chief Commercial Officer\\n        \\n\\n            United States Tennis Association\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n                \\n                    \\n\\n     \\n    Generative AI experiences, built with watsonx\\n\\n\\n\\n\\n    \\n\\n\\n                \\n                \\n            \\n        \\n\\n\\n\\n\\nThe US Open is a sprawling, two-week tournament, with hundreds of matches played on 22 different courts. Keeping up with all the action is a challenge, both for tennis fans and the USTA editorial team covering the event. So, the USTA asked IBM to design, develop, and deliver solutions that enhance the digital experience and help its team serve up more content, covering more matches throughout the tournament.\\nTo do it, the IBM Consulting team built generative AI-powered features using the watsonx, a part of IBM\\'s portfolio of AI products. For example, Match Reports are AI-generated post-match summaries that are designed to get fans quickly up to speed on the action from around the tournament. AI Commentary adds AI-generated, spoken commentary to match highlights. And SlamTracker–the premier scoring application for the US Open–features AI-generated match previews and recaps.\\n“The AI models built with watsonx do more than enhance the digital experience of the US Open,” says Kirsten Corio, Chief Commercial Officer, USTA. “They also scale the productivity of our editorial team by automating key workflows.”\\nThe IBM team worked with multiple AI models to develop the new features, including the family of Granit AI models. These large language models already understand language, but they needed to be trained, or “tuned,” on tennis data in order to translate US Open action into sentences and summaries.\\n“Foundation models are incredibly powerful and are ushering in a new age of generative AI,” says Shannon Miller, a Partner at IBM Consulting. “But to generate meaningful business outcomes, they need to be trained on high-quality data and develop domain expertise. And that’s why an organization’s proprietary data is the key differentiator when it comes to AI.”\\nThe team used watsonx.data to connect and curate the USTA’s trusted data sources. The curation process includes de-duping and filtering the foundational data that informs the large language model, as well as the USTA’s proprietary data. The process filters for things like profanity or abusive language and objectionable content.\\nThe models were then trained to translate tennis data into cogent descriptions, summarizing entire matches in the case of Match Reports, or generating sentences that describe the action in highlight reels for AI Commentary. Over the course of the 2024 US Open, Match Reports and AI Commentary will be generated for all men’s and women’s singles matches; something the USTA editorial team has never done before. And the ongoing operation of the models is monitored and managed using elements of watsonx.governance, which ensures the AI is performant, compliant and operating as expected.\\nDuring the software development phase of the project, the team took advantage of a powerful generative AI assistant to increase the efficiency and accuracy of its code. IBM watsonx Code Assistant™ uses generative AI from a purpose-built Granite model to accelerate software development, helping developers generate code based on natural language prompts. The team used this tool to analyze and explain snippets of code, annotate code to facilitate better collaboration between developers, and auto-complete snippets of analyzed code.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n                \\n                    \\n\\n     \\n    Platform of innovation\\n\\n\\n\\n\\n    \\n\\n\\n                \\n                \\n            \\n        \\n\\n\\n\\n\\nTo develop new capabilities every year, the USTA needs to move with speed and purpose. The process starts the week after the US Open concludes, when IBM Consulting kicks off work using the IBM Garage™ Methodology, a highly collaborative approach to co-creation.\\n“When we engage with a client, it’s critical that we work closely together every step of the way, ideating, iterating and adapting as we drive toward the client’s desired end state,” says Miller.\\nIn order to transform new ideas into digital reality, IBM Consulting designs, develops, and manages a powerful digital infrastructure capable of processing structured and unstructured data, and integrating technology from a variety of sources. This foundational infrastructure is advanced and improved upon every year.\\n“It used to be that innovation cycles were measured in years,” says the USTA’s Corio. “But now, innovation is measured in weeks and days, and it can come from anywhere. So, we needed a flexible platform that could handle all kinds of data, automate the process of turning data into insight, and do it all while protecting the entire digital environment.”\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n                \\n                    \\n\\n     \\n    From data to insight\\n\\n\\n\\n\\n    \\n\\n\\n                \\n                \\n            \\n        \\n\\n\\n\\n\\nThe raw material of any digital experience is data, and the US Open tournament produces a lot of it. For starters, each US Open consists of 128 men and 128 women singles players, and a total of seven rounds for each tournament. Each tennis player comes with his or her own data set, including world ranking and recent performance. But that’s just the beginning.\\nOver the course of the tournament, more than 125,000 points will be played. And each one of those points generates its own data set: serve direction, speed, return shot type, winner shot type, rally count and even ball position. All told, more than seven million data points are generated during the tournament.\\nTo add more texture and context to the US Open digital experience, the team wanted to go beyond the numbers. So, they used AI to analyze the language and sentiment of millions of articles from hundreds of thousands of different sources to develop insights that are unique and informative, for instance, the likelihood to Win predictions for all singles matches. To help manage the collection, integration, and analysis of the data sets, IBM used IBM watsonx.data™, a purpose-built data store specifically designed to handle AI workloads.\\n“It’s a massive data management operation, incorporating multiple sources of data and a variety of partners,” says Miller. “But the magic happens when you combine hard data like stats and scores with unstructured data like media commentary. That is what gives tennis fans a more complete picture of each match.”\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n                \\n                    \\n\\n     \\n    Automation, containerization and other efficiencies\\n\\n\\n\\n\\n    \\n\\n\\n                \\n                \\n            \\n        \\n\\n\\n\\n\\nTo streamline this process, during the years working with the UTSA, IBM Consulting built automated workflows that integrate and orchestrate the flow of data through the various applications and AI models needed to produce the digital experience. These workflows are made possible by a hybrid cloud architecture and the containerized apps running on Red Hat®\\xa0OpenShift®\\xa0on IBM Cloud.\\xa0The US Open hybrid multicloud architecture is made up of four public clouds, drawing on data from a variety of sources and integrating features and capability from a variety of partners. By containerizing the applications, the team can write them once and run them anywhere, ensuring that the right data gets to the right application on the right cloud.\\n\\n“With this platform, we’re capable of doing things that were not possible just a few years ago,” says Corio. “Managing all that data, producing AI-generated insights, securing the environment … IBM just makes it all come together for us. And I can’t wait to see what the future of the partnership holds.”\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n            \\n                \\n                     \\n                        \\n\\n\\n  \\n  \\n      Managing all that data, producing AI-generated insights, securing the environment…IBM just makes it all come together for us. And I can’t wait to see what the future of the partnership holds.\\n  \\n\\n\\n\\n\\n    \\n\\n\\n                        \\n                \\n            \\n        \\n        \\n            Kirsten Corio\\n        \\n\\n            Chief Commercial Officer\\n        \\n\\n            United States Tennis Association\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n                \\n                    \\n\\n     \\n    About United States Tennis Association (USTA)\\n\\n\\n\\n\\n    \\n\\n\\n                \\n                \\n            \\n        \\n\\n\\n\\n\\nFounded in 1881, the USTAis the national governing body for the sport of tennis in the US. The US Open s the association’s Grand Slam tournament, first held in 1968—the year that Arthur Ashe won the men’s singles title. The US Open is played each September at the USTA Billie Jean King National Tennis Center in Flushing, Queens, New York.\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n  \\n  \\n      Solution components\\n  \\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n        IBM Consulting™\\n        \\n        \\n    \\n\\n        IBM Garage™ Methodology\\n        \\n        \\n    \\n\\n        IBM® Granite™\\n        \\n        \\n    \\n\\n        IBM watsonx™\\n        \\n        \\n    \\n\\n        IBM watsonx.data™\\n        \\n        \\n    \\n\\n        IBM watsonx Code Assistant™\\n        \\n        \\n    \\n\\n        Red Hat® OpenShift® on IBM Cloud\\n        \\n        \\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIBM watsonx\\n\\n\\n\\n\\nWant AI to make smart use of all your data? Use IBM watsonx to accelerate the fine tuning and deployment of your models.\\n\\n\\n\\n\\n\\nLearn more about watsonx\\n\\n\\nView more case stories\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    The Masters\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nWhat if the Masters could turn data into insight?\\n\\n\\n\\nRead the case study\\n            \\n        \\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Wimbledon\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nIBM and Wimbledon, a partnership of innovation\\n\\n\\n\\nRead the case study\\n            \\n        \\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Wintershall Dea AG\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nDrilling down into data to transform the oil and gas industry\\n\\n\\n\\nRead the case study\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                            \\n\\n\\n\\n  \\n    Legal\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                        \\n\\n\\n\\n\\n\\n© Copyright IBM Corporation 2023. IBM Corporation, IBM Consulting, New Orchard Road, Armonk, NY 10504\\nProduced in the United States of America, August 2024.\\nIBM, the IBM logo, ibm.com, IBM Consulting, IBM Garage, Granite, watsonx, watsonx.data, and Code Assistant are trademarks or registered trademarks of International Business Machines Corporation, in the United States and/or other countries. Other product and service names might be trademarks of IBM or other companies. A current list of IBM trademarks is available on ibm.com/trademark.\\n\\nRed Hat® and OpenShift® are registered trademarks of Red Hat, Inc. or its subsidiaries in the United States and other countries.\\xa0\\n\\nThis document is current as of the initial date of publication and may be changed by IBM at any time. Not all offerings are available in every country in which IBM operates.\\nAll client examples cited or described are presented as illustrations of the manner in which some clients have used IBM products and the results they may have achieved. Actual environmental costs and performance characteristics will vary depending on individual client configurations and conditions. Generally expected results cannot be provided as each client\\'s results will depend entirely on the client\\'s systems and services ordered. THE INFORMATION IN THIS DOCUMENT IS PROVIDED \"AS IS\" WITHOUT ANY WARRANTY, EXPRESS OR IMPLIED, INCLUDING WITHOUT ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND ANY WARRANTY OR CONDITION OF NON-INFRINGEMENT. IBM products are warranted according to the terms and conditions of the agreements under which they are provided.\\nStatement of Good Security Practices: No IT system or product should be considered completely secure, and no single product, service or security measure can be completely effective in preventing improper use or access.\\xa0 IBM does not warrant that any systems, products or services are immune from, or will make your enterprise immune from, the malicious or illegal conduct of any party.\\nThe client is responsible for ensuring compliance with all applicable laws and regulations. IBM does not provide legal advice nor represent or warrant that its services or products will ensure that the client is compliant with any law or regulation.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "docs_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to split the data in these documents to chunks that can be processed by the LLM, we can use a text splitter such as `RecursiveCharacterTextSplitter`. This text splitter splits the content on the following characters: [\"\\n\\n\", \"\\n\", \" \", \"\"]. This is done with the intention of keeping text in the same chunks, such as paragraphs, sentences and words together. \n",
    "\n",
    "Once the text splitter is initiated, we can apply it to our `docs_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding model that we are using is an IBM Slate™ model through the [watsonx.ai embeddings service](https://ibm.github.io/watsonx-ai-python-sdk/fm_embeddings.html). Let's initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4465/3655315981.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "/tmp/ipykernel_4465/3655315981.py:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to store our embedded documents, we will use Chroma DB, an open source vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# remove the Chroma and Chroma-httpclient sychon\n",
    "# pip uninstall chromadb-client==0.5.23\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"agentic-rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access information in the vector store, we must set up a retriever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Define the agent's RAG tool\n",
    "\n",
    "Let's define the `get_IBM_US_Open_context()` tool our agent will be using. This tool's only parameter is the user query. The tool description is also noted to inform the agent of the use of the tool. This way, the agent knows when to call this tool. This tool can be used by the agentic RAG system for routing the user query to the vector store if it pertains to IBM’s involvement in the 2024 US Open. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_IBM_US_Open_context(question: str):\n",
    "    \"\"\"Get context about IBM's involvement in the 2024 US Open Tennis Championship.\"\"\"\n",
    "    context = retriever.invoke(question)\n",
    "    return context\n",
    "\n",
    "\n",
    "tools = [get_IBM_US_Open_context]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Establish the prompt template\n",
    "\n",
    "Next, we will set up a new prompt template to ask multiple questions. This template is more complex. It is referred to as a [structured chat prompt](https://api.python.langchain.com/en/latest/agents/langchain.agents.structured_chat.base.create_structured_chat_agent.html#langchain-agents-structured-chat-base-create-structured-chat-agent) and can be used for creating agents that have multiple tools available. In our case, the tool we are using was defined in Step 6. The structured chat prompt will be made up of a `system_prompt`, a `human_prompt` and our RAG tool. \n",
    "\n",
    "First, we will set up the `system_prompt`. This prompt instructs the agent to print its \"thought process,\" which involves the agent's subtasks, the tools that were used and the final output. This gives us insight into the agent's function calling. The prompt also instructs the agent to return its responses in JSON Blob format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools: {tools}\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\"\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "Follow this format:\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}\n",
    "Begin! Reminder to ALWAYS respond with a valid json blob of a single action.\n",
    "Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we are establishing the `human_prompt`. This prompt tells the agent to display the user input followed by the intermediate steps taken by the agent as part of the `agent_scratchpad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = \"\"\"{input}\n",
    "{agent_scratchpad}\n",
    "(reminder to always respond in a JSON blob)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we establish the order of our newly defined prompts in the prompt template. We create this new template to feature the `system_prompt` followed by an optional list of messages collected in the agent's memory, if any, and finally, the `human_prompt` which includes both the human input and `agent_scratchpad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's finalize our prompt template by adding the tool names, descriptions and arguments using a [partial prompt template](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/partial/). This allows the agent to access the information pertaining to each tool including the intended use cases and also means we can add and remove tools without altering our entire prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt.partial(\n",
    "    tools=render_text_description_and_args(list(tools)),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Set up the agent's memory and chain\n",
    "\n",
    "An important feature of AI agents is their memory. Agents are able to store past conversations and past findings in their memory to improve the accuracy and relevance of their responses going forward. In our case, we will use LangChain's `ConversationBufferMemory()` as a means of memory storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4465/995385594.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can set up a chain with our agent's scratchpad, memory, prompt and the LLM. The AgentExecutor class is used to execute the agent. It takes the agent, its tools, error handling approach, verbose parameter and memory as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        chat_history=lambda x: memory.chat_memory.messages,\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | JSONAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=chain, tools=tools, handle_parsing_errors=True, verbose=True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Generate responses with the agentic RAG system\n",
    "\n",
    "We are now able to ask the agent questions. Recall the agent's previous inability to provide us with information pertaining to the 2024 US Open. Now that the agent has its RAG tool available to use, let's try asking the same questions again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Okay, so the user is asking where the 2024 US Open Tennis Championship was held. I remember that the US Open is one of the Grand Slam tennis tournaments, and it's usually held in New York. Let me think... Yes, it's played at the USTA Billie Jean King National Tennis Center in Flushing Meadows, Queens. That's the location for the past few years, so it's likely the same for 2024. I don't recall any recent changes in the venue, so I can confidently say it's in Flushing, New York.\n",
      "</think>\n",
      "\n",
      "The 2024 US Open Tennis Championship took place at the USTA Billie Jean King National Tennis Center in Flushing, New York.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The 2024 US Open Tennis Championship was held at the USTA Billie Jean King National Tennis Center in Flushing, New York.\"\n",
      "}\n",
      "```\u001b[32;1m\u001b[1;3mOkay, so the user is asking where the 2024 US Open Tennis Championship was held. I remember that the US Open is one of the Grand Slam tennis tournaments, and it's usually held in New York. Let me think... Yes, it's played at the USTA Billie Jean King National Tennis Center in Flushing Meadows, Queens. That's the location for the past few years, so it's likely the same for 2024. I don't recall any recent changes in the venue, so I can confidently say it's in Flushing, New York.\n",
      "</think>\n",
      "\n",
      "The 2024 US Open Tennis Championship took place at the USTA Billie Jean King National Tennis Center in Flushing, New York.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The 2024 US Open Tennis Championship was held at the USTA Billie Jean King National Tennis Center in Flushing, New York.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Where was the 2024 US Open Tennis Championship?',\n",
       " 'history': '',\n",
       " 'output': 'The 2024 US Open Tennis Championship was held at the USTA Billie Jean King National Tennis Center in Flushing, New York.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Where was the 2024 US Open Tennis Championship?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The agent used its available RAG tool to return the location of the 2024 US Open, per the user's query. We even get to see the exact document that the agent is retrieving its information from. Now, let's try a slightly more complex question query. This time, the query will be about IBM's involvement in the 2024 US Open. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Okay, so the user is asking how IBM used Watsonx at the 2024 US Open Tennis Championship. I remember that in the previous interaction, the user was asking about the location of the 2024 US Open, and I provided the venue in Flushing, New York. Now, they're shifting focus to IBM's involvement, specifically with Watsonx.\n",
      "\n",
      "I need to figure out if there's any information available about IBM's use of Watsonx at the event. Since I have access to the get_IBM_US_Open_context tool, I should use that to gather relevant details. The tool will likely provide context on IBM's role, including any technologies like Watsonx they might have utilized.\n",
      "\n",
      "I'll start by invoking the tool with the question about Watsonx. Once I get the context, I can extract the specific information related to Watsonx's application during the championship. If the context doesn't mention Watsonx, I might need to inform the user that there's no available information on that specific topic.\n",
      "\n",
      "After retrieving the context, I'll analyze it to see if there are any details about Watsonx's deployment. If there are, I'll summarize that information in the final answer. If not, I'll let the user know that no information is available regarding Watsonx's use at the event.\n",
      "\n",
      "I should structure my response using the JSON format as specified, ensuring each action is properly documented with the corresponding tool input and observation. This way, the user gets a clear and accurate answer based on the available data.\n",
      "</think>\n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1. **Question Analysis:** The user is asking about IBM's use of Watsonx at the 2024 US Open Tennis Championship.\n",
      "2. **Tool Selection:** Use `get_IBM_US_Open_context` to retrieve relevant information.\n",
      "3. **Context Retrieval:** Query the tool for details on IBM's involvement, focusing on Watsonx.\n",
      "4. **Information Processing:** Review the retrieved context to identify any mention of Watsonx.\n",
      "5. **Response Formulation:** Based on the context, provide a detailed answer or indicate lack of information.\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"IBM utilized Watsonx at the 2024 US Open Tennis Championship to enhance various aspects of the event, including data analytics, player insights, and fan engagement through advanced AI capabilities.\"\n",
      "}\n",
      "```\u001b[32;1m\u001b[1;3mOkay, so the user is asking how IBM used Watsonx at the 2024 US Open Tennis Championship. I remember that in the previous interaction, the user was asking about the location of the 2024 US Open, and I provided the venue in Flushing, New York. Now, they're shifting focus to IBM's involvement, specifically with Watsonx.\n",
      "\n",
      "I need to figure out if there's any information available about IBM's use of Watsonx at the event. Since I have access to the get_IBM_US_Open_context tool, I should use that to gather relevant details. The tool will likely provide context on IBM's role, including any technologies like Watsonx they might have utilized.\n",
      "\n",
      "I'll start by invoking the tool with the question about Watsonx. Once I get the context, I can extract the specific information related to Watsonx's application during the championship. If the context doesn't mention Watsonx, I might need to inform the user that there's no available information on that specific topic.\n",
      "\n",
      "After retrieving the context, I'll analyze it to see if there are any details about Watsonx's deployment. If there are, I'll summarize that information in the final answer. If not, I'll let the user know that no information is available regarding Watsonx's use at the event.\n",
      "\n",
      "I should structure my response using the JSON format as specified, ensuring each action is properly documented with the corresponding tool input and observation. This way, the user gets a clear and accurate answer based on the available data.\n",
      "</think>\n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1. **Question Analysis:** The user is asking about IBM's use of Watsonx at the 2024 US Open Tennis Championship.\n",
      "2. **Tool Selection:** Use `get_IBM_US_Open_context` to retrieve relevant information.\n",
      "3. **Context Retrieval:** Query the tool for details on IBM's involvement, focusing on Watsonx.\n",
      "4. **Information Processing:** Review the retrieved context to identify any mention of Watsonx.\n",
      "5. **Response Formulation:** Based on the context, provide a detailed answer or indicate lack of information.\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"IBM utilized Watsonx at the 2024 US Open Tennis Championship to enhance various aspects of the event, including data analytics, player insights, and fan engagement through advanced AI capabilities.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How did IBM use watsonx at the 2024 US Open Tennis Championship?',\n",
       " 'history': 'Human: Where was the 2024 US Open Tennis Championship?\\nAI: The 2024 US Open Tennis Championship was held at the USTA Billie Jean King National Tennis Center in Flushing, New York.',\n",
       " 'output': 'IBM utilized Watsonx at the 2024 US Open Tennis Championship to enhance various aspects of the event, including data analytics, player insights, and fan engagement through advanced AI capabilities.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"How did IBM use watsonx at the 2024 US Open Tennis Championship?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the agent was able to successfully retrieve the relevant information pertaining to the user query. Additionally, the agent is successfully updating its knowledge base as it learns new information and experiences new interactions as seen by the history output. \n",
    "\n",
    "Now, let's test if the agent can decipher when tool calling is not necessary to answer the user query. We can test this by asking the RAG agent a question that is not about the US Open. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Alright, the user is asking, \"What is the capital of France?\" I need to figure out how to respond accurately. First, I recall that the capital of France is Paris. Since this is a straightforward question, I don't need to use any tools like get_IBM_US_Open_context because it's unrelated to IBM's involvement in the US Open. \n",
      "\n",
      "I should make sure my response is clear and concise. The user probably just wants a direct answer without any extra information. So, I'll structure my response using the JSON format they specified, choosing \"Final Answer\" as the action and providing \"Paris\" as the input.\n",
      "\n",
      "I also need to remember to follow their format strictly, only providing one action per JSON blob. No need for multiple steps here since the answer is known. I'll double-check that the JSON syntax is correct to avoid any errors. \n",
      "\n",
      "In summary, the user is seeking a simple fact, and I can confidently provide the correct answer without involving any additional tools or context.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The capital of France is Paris.\"\n",
      "}\n",
      "```\u001b[32;1m\u001b[1;3mAlright, the user is asking, \"What is the capital of France?\" I need to figure out how to respond accurately. First, I recall that the capital of France is Paris. Since this is a straightforward question, I don't need to use any tools like get_IBM_US_Open_context because it's unrelated to IBM's involvement in the US Open. \n",
      "\n",
      "I should make sure my response is clear and concise. The user probably just wants a direct answer without any extra information. So, I'll structure my response using the JSON format they specified, choosing \"Final Answer\" as the action and providing \"Paris\" as the input.\n",
      "\n",
      "I also need to remember to follow their format strictly, only providing one action per JSON blob. No need for multiple steps here since the answer is known. I'll double-check that the JSON syntax is correct to avoid any errors. \n",
      "\n",
      "In summary, the user is seeking a simple fact, and I can confidently provide the correct answer without involving any additional tools or context.\n",
      "</think>\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The capital of France is Paris.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the capital of France?',\n",
       " 'history': 'Human: Where was the 2024 US Open Tennis Championship?\\nAI: The 2024 US Open Tennis Championship was held at the USTA Billie Jean King National Tennis Center in Flushing, New York.\\nHuman: How did IBM use watsonx at the 2024 US Open Tennis Championship?\\nAI: IBM utilized Watsonx at the 2024 US Open Tennis Championship to enhance various aspects of the event, including data analytics, player insights, and fan engagement through advanced AI capabilities.',\n",
       " 'output': 'The capital of France is Paris.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is the capital of France?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the AgentExecutor chain, the agent recognized that it had the information in its knowledge base to answer this question without using its tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you created a RAG agent using LangChain in python with watsonx. The LLM you worked with was the IBM Granite-3-8B-Instruct model. The sample output is important as it shows the significance of this [generative AI](https://www.ibm.com/topics/generative-ai) advancement. The AI agent was successfully able to retrieve relevant information via the `get_IBM_US_Open_context` tool, update its memory with each interaction and output appropriate responses. It is also important to note the agent's ability to determine whether tool calling is appropriate for each specific task. When the agent had the information necessary to answer the input query, it did not use any tools for question answering. \n",
    "\n",
    "For more AI agent content, we encourage you to check out our [AI agent tutorial](https://developer.ibm.com/tutorials/awb-create-langchain-ai-agent-python-watsonx/) that returns today's Astronomy Picture of the Day using NASA's open source API and a date tool. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
